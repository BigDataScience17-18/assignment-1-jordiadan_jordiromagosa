{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "### Authors\n",
    "* Jordi Mellado Romagosa \n",
    "* Jordi Adan Dom√≠nguez\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_row_reduction_data(filename):\n",
    "    # read data\n",
    "    df = pd.read_csv(filepath_or_buffer='engineered/' + filename + '.csv',\n",
    "                     header=None,\n",
    "                     sep=\",\",\n",
    "                     low_memory=False)\n",
    "    \n",
    "    df = df.loc[:, [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]\n",
    "    df.columns = ['Class', 'Min', 'Max', 'Sd', 'Mean', 'Median', 'IQR', 'Q(0.025)', 'Q(0.25)', 'Q(0.75)', 'Q(0.975)']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_column_reduction_data(filename):\n",
    "    # read data\n",
    "    df = pd.read_csv(filepath_or_buffer='engineered/' + filename + '.csv',\n",
    "                     header=None,\n",
    "                     sep=\",\")\n",
    "    \n",
    "    df = df.drop(df.columns[[0, 2, 3]], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "### PCA (with row reduction)\n",
    "\n",
    "columns = ['Min', 'Max', 'Sd', 'Mean', 'Median', 'IQR', 'Q(0.025)', 'Q(0.25)', 'Q(0.75)', 'Q(0.975)']  \n",
    "rows = Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_row_reduction(filename):\n",
    "    \n",
    "    # read data\n",
    "    df = read_row_reduction_data(filename)\n",
    "    \n",
    "    # split data table into data X and class labels y\n",
    "    X = df.ix[:, 1:].values\n",
    "    y = df.ix[:, 0].values\n",
    "    \n",
    "    # standardizing data\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    sklearn_pca = PCA(svd_solver='auto')\n",
    "    Y_sklearn = sklearn_pca.fit_transform(X_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (with column reduction)\n",
    "\n",
    "columns = Sensor value records(255)  \n",
    "rows = Average of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_column_reduction(filename):\n",
    "    \n",
    "    # read data\n",
    "    df = read_column_reduction_data(filename)\n",
    "    print(df)\n",
    "    \n",
    "    # split data table into data X and class labels y\n",
    "    X = df.ix[:, 4:].values\n",
    "    y = df.ix[:, 1].values\n",
    "    \n",
    "    # standardizing data\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    sklearn_pca = PCA(svd_solver='auto')\n",
    "    Y_sklearn = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_row_reduction('train_alcoholic_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1         4         5         6         7         8         9    \\\n0      a -0.653350 -0.592275 -0.543350 -0.567950 -0.519050 -0.519050   \n1      a -0.233000 -0.269600 -0.428225 -0.367225 -0.086500  0.084450   \n2      a -2.521950 -1.398925  0.004800  0.883775  0.761700 -0.080600   \n3      a -0.150550 -1.334600 -1.615350 -0.834150  0.276650  0.447575   \n4      a -0.446850 -0.446850 -0.507900 -0.349100 -0.166050 -0.104975   \n5      a  0.774675  0.103275  0.200975  0.286350  0.945525  0.139825   \n6      a  0.369975 -0.338025 -0.167075 -0.350225  0.064850  0.125925   \n7      a  0.770075 -0.047750  0.428275 -0.230925  0.965350 -1.109850   \n8      a -0.285850 -0.932825 -0.542250 -1.042675 -0.481125  0.214625   \n9      a  0.291675  0.267375  0.364950  0.584750  0.609100  0.120775   \n10     a  0.527750  0.271375  0.002825 -0.229100 -0.424475 -0.509950   \n11     a  0.101225  0.247700  0.357500  0.418550  0.333125  0.247650   \n12     a  0.306475  0.294325  0.343075  0.343050  0.269800  0.160000   \n13     a  0.411500  0.667900  0.667825  0.387000  0.069650 -0.015725   \n14     a  0.477575  0.404350  0.367600  0.331100  0.160250  0.050300   \n15     a -0.377175 -1.194975 -1.207250  0.452900  0.269850  1.795700   \n16     a  0.103700 -1.092425 -1.617400 -1.483075 -0.567550  0.482100   \n17     a  0.257575  0.306450  0.416250  0.428550  0.416325  0.404025   \n18     a  0.767025  2.073175  3.757700  5.137150  5.503325  4.563425   \n19     a -0.373075 -0.238800 -0.141125 -0.043425  0.005300 -0.067875   \n20     a  0.011400 -0.061725 -0.122800 -0.159450 -0.232700 -0.305975   \n21     a -0.663275 -0.370275 -0.101700  0.081375  0.093600  0.020375   \n22     a  0.352150  0.120300 -0.136100 -0.441325 -0.734200 -0.856225   \n23     a -0.746375 -0.355825  0.059225  0.156900  0.132425 -0.026225   \n24     a  0.932300  0.419625 -0.190650 -0.752200 -1.338125 -1.679950   \n25     a -1.084825 -0.462350  0.331100  1.112325  1.283225  0.758300   \n26     a  0.689900  1.153775  0.665500 -0.323275 -0.896925 -0.884825   \n27     a -0.408450 -0.322950 -0.066625  0.104225  0.079875 -0.066575   \n28     a  0.029975 -0.006625 -0.055500 -0.140975 -0.275125 -0.458325   \n29     a -0.571725 -0.229975 -0.034650  0.136325  0.197350  0.160700   \n...   ..       ...       ...       ...       ...       ...       ...   \n4130   a  0.329828  0.228759 -0.023966 -0.242759 -0.108103  0.447552   \n4131   a  0.844724  1.316138  1.770793  1.854966  1.753828  1.636069   \n4132   a  0.441966  0.559862  0.711345  0.963931  1.233310  1.586966   \n4133   a -0.168690  0.050276  0.386931  0.521655  0.470966  0.319586   \n4134   a  0.936621  0.599828  0.145276 -0.023069  0.229414  0.734483   \n4135   a  0.321586  0.490069  0.591069  0.490103  0.388966  0.372172   \n4136   a  0.300552  0.570000  0.805759  0.990931  0.974103  0.772069   \n4137   a  0.228690  0.127690  0.161345  0.262379  0.312931  0.363414   \n4138   a  0.400517  0.467931  0.535345  0.703586  0.703655  0.653103   \n4139   a  0.285586  0.319172  0.420345  0.521241  0.538138  0.504414   \n4140   a  0.252966  0.101414  0.034000  0.017103  0.050862  0.168690   \n4141   a  0.223724  0.257517  0.425862  0.577414  0.476310  0.409034   \n4142   a  0.201345 -0.000759 -0.236414 -0.253276 -0.118552  0.066690   \n4143   a  0.179966  0.466172  0.483069  0.584172  0.483000  0.449310   \n4144   a  0.024586 -0.312241 -0.463828 -0.345862 -0.127034  0.176138   \n4145   a  0.419552  0.419414  0.470000  0.571069  0.604759  0.520448   \n4146   a -0.060379 -0.514931 -0.767379 -0.733862 -0.481172 -0.161345   \n4147   a  0.067000  0.201724  0.336414  0.572103  0.572103  0.521621   \n4148   a  0.283448  0.216069  0.131897  0.165517  0.182483  0.081379   \n4149   a  0.345483  0.564414  0.884276  1.069586  1.035793  0.850690   \n4150   a  0.178552 -0.107724 -0.343448 -0.377000 -0.259172 -0.107724   \n4151   a  0.008828  0.076172  0.143345  0.345483  0.429759  0.328828   \n4152   a  0.143414  0.076138  0.076103  0.143345  0.092793  0.076138   \n4153   a  0.163517  0.449621  0.719103  0.837000  0.685483  0.415966   \n4154   a  0.162414  0.162414  0.263414  0.398138  0.364483  0.465586   \n4155   a  0.441897  0.728241  1.031310  1.081793  0.879759  0.627207   \n4156   a -0.127069 -0.396414 -0.480483 -0.379586 -0.110138  0.091897   \n4157   a  0.541897  0.154621  0.070517  0.474690  1.097655  1.686828   \n4158   a  0.192517  0.529310  0.882931  1.169172  1.286897  1.354310   \n4159   a  0.310345  0.546103  0.815621  1.000793  1.000828  0.731448   \n\n           10        11        12     ...          250       251       252  \\\n0    -0.482425 -0.555650 -0.604525    ...     4.070825  3.912075  4.009700   \n1    -0.135200 -0.672375 -1.087525    ...     3.099525  2.794350  2.843175   \n2    -1.069425 -1.692025 -1.679750    ...     7.390100  7.414475  7.512175   \n3    -1.102650 -3.202400 -4.288750    ...     7.588675  6.172675  4.134200   \n4    -0.153875 -0.288175 -0.361300    ...     3.569200  3.361700  3.386275   \n5     1.018775  0.579250  0.225300    ...    -0.751250 -0.531450 -0.397175   \n6    -0.252550 -0.374550  0.211350    ...     0.260225  0.235750  0.150250   \n7     2.222700  1.160675  0.220750    ...    -1.781175 -1.012175 -0.523850   \n8    -0.346850 -0.371375  0.397775    ...     0.458825  0.568675 -0.017375   \n9    -0.733700 -1.160900 -0.660500    ...    -2.515900 -2.076525 -1.112075   \n10   -0.644025 -0.680800 -0.607650    ...    -0.937150 -1.083625 -1.010425   \n11    0.259900  0.308700  0.320925    ...    -0.692250 -0.728900 -0.765550   \n12   -0.035350 -0.181875 -0.267300    ...    -0.218450 -0.230600 -0.145225   \n13    0.167325  0.277250  0.277250    ...    -1.529475 -1.529400 -1.614875   \n14   -0.242600 -0.413475 -0.547725    ...    -1.255825 -1.219150 -1.231350   \n15    3.309400  0.123400 -0.230675    ...    -2.269225 -1.268150 -1.109550   \n16   -0.555325 -0.567625  0.555450    ...    -1.776200 -1.629650 -1.739425   \n17    0.294250  0.184325  0.184400    ...    -0.462575 -0.425950 -0.425950   \n18    2.891025  1.621475  1.487250    ...     2.988675  2.976475  3.330375   \n19   -0.153400 -0.165500 -0.055725    ...     0.676750  0.481425  0.469200   \n20   -0.281500  0.096900  0.487475    ...     0.109125  0.597400  0.939175   \n21   -0.138375 -0.150650 -0.028450    ...     0.874775  0.789450  0.667275   \n22   -0.734175 -0.111650  0.572000    ...    -0.050575  0.571900  1.341050   \n23   -0.087225 -0.014075  0.047000    ...     1.011350  0.779450  0.889400   \n24   -1.264900 -0.325000  0.883425    ...     0.212075  1.115350  1.933300   \n25   -0.303625 -1.084900 -1.048300    ...     2.503900  2.650475  2.894525   \n26   -0.347675 -0.152275 -0.603975    ...     4.620600  3.338800  0.958450   \n27   -0.152125 -0.115475  0.030975    ...    -0.286400 -0.274150 -0.261975   \n28   -0.494825 -0.421675 -0.116525    ...    -0.397225 -0.238600 -0.079875   \n29    0.063050  0.038650  0.038600    ...    -0.535050 -0.779225 -0.803700   \n...        ...       ...       ...    ...          ...       ...       ...   \n4130  1.239000  1.895690  2.114483    ...    -1.556034 -1.522276 -1.707483   \n4131  1.585552  1.467690  1.467690    ...    -2.253345 -2.017621 -1.832379   \n4132  1.856172  1.991000  1.906862    ...    -2.622414 -2.454000 -2.420310   \n4133  0.252276  0.353172  0.555276    ...    -2.071276 -2.020862 -1.801931   \n4134  1.003828  1.088069  0.835586    ...    -1.016586 -0.898690 -0.494621   \n4135  0.523690  0.759345  0.944724    ...    -1.463207 -1.547345 -1.513724   \n4136  0.553241  0.435276  0.384862    ...    -1.501034 -1.181034 -0.861207   \n4137  0.262276  0.245517  0.262448    ...    -1.539241 -1.168724 -1.000552   \n4138  0.451207  0.299655  0.232276    ...    -1.720966 -1.417897 -1.131517   \n4139  0.386552  0.218138  0.117138    ...     1.464172  1.531517  1.548345   \n4140  0.168724  0.135069  0.034103    ...     0.791655  0.842207  0.859069   \n4141  0.190138  0.206897  0.122759    ...     0.728897  0.762621  0.897310   \n4142  0.302345  0.302310  0.235034    ...     0.790655  0.740138  0.773793   \n4143  0.415655  0.432552  0.314724    ...    -0.072517 -0.038897  0.146310   \n4144  0.176138  0.159276  0.058241    ...    -0.716207 -0.716276 -0.514310   \n4145  0.554276  0.705759  0.739414    ...    -1.196862 -1.011655 -0.843172   \n4146  0.074345  0.175414  0.141655    ...    -1.643069 -1.659862 -1.407345   \n4147  0.336276  0.218483  0.033379    ...     0.336448  0.437379  0.504897   \n4148 -0.002793 -0.221759 -0.373207    ...     0.030828  0.081345  0.115000   \n4149  0.665448  0.446586  0.396034    ...    -1.456103 -1.136138 -0.833138   \n4150  0.043862  0.144862  0.094345    ...    -3.172069 -3.071034 -2.801655   \n4151  0.227690  0.008759 -0.109138    ...     0.985345  1.002172  1.019103   \n4152  0.092862 -0.109172 -0.159690    ...     1.928207  1.894552  1.945103   \n4153  0.298138  0.298172  0.533931    ...    -1.318069 -1.301379 -1.200379   \n4154  0.650655  0.936931  1.172655    ...    -1.150828 -0.932069 -0.662655   \n4155  0.475655  0.543034  0.694586    ...    -1.224966 -1.056552 -0.905034   \n4156  0.327690  0.462345  0.563345    ...    -1.170931 -1.170931 -1.069759   \n4157  1.973103  2.141586  2.259241    ...    -3.465345 -3.128552 -2.859241   \n4158  1.488931  1.775310  2.162552    ...    -2.652828 -2.551862 -2.383483   \n4159  0.546103  0.445034  0.445172    ...    -1.457448 -1.188103 -0.817655   \n\n           253       254       255       256       257       258       259  \n0     4.034100  3.692425  3.301625  3.008750  3.021025  3.387175  3.704550  \n1     3.038500  3.185025  3.111775  2.940900  2.867650  3.062875  3.404800  \n2     7.353475  6.828475  6.096200  5.510200  5.620000  6.096050  6.572225  \n3     2.718100  2.376250  3.108800  4.207350  5.330375  6.197200  6.624350  \n4     3.459525  3.447175  3.337350  3.129800  2.971125  3.032150  3.203025  \n5    -0.629200 -1.825500 -0.030925 -0.555900 -0.446075 -0.470500 -0.006650  \n6     0.162500 -0.948375 -0.118300  0.321200 -0.057225  0.748375 -0.191500  \n7    -0.316425 -0.499400 -0.133275 -1.195250 -0.694875 -1.366200  0.281775  \n8    -0.237025  1.484150 -0.737475  1.508575  0.202500  1.447575 -0.847375  \n9    -0.514000 -0.880150 -1.685825 -2.161925 -1.893350 -1.222050 -0.965600  \n10   -0.876200 -0.888400 -0.937150 -0.924925 -0.656375 -0.265800 -0.021700  \n11   -0.606775 -0.387100 -0.313900 -0.240600 -0.338325 -0.533600 -0.558000  \n12   -0.108625  0.123350  0.233175  0.306550  0.379725  0.257625  0.294300  \n13   -1.505025 -1.309700 -1.065575 -0.992300 -1.138850 -1.346300 -1.431725  \n14   -1.158175 -1.060475 -0.865125 -0.706525 -0.572175 -0.572175 -0.535575  \n15   -1.195050 -2.452350 -2.049500 -2.989400 -2.806350 -0.584625 -0.462575  \n16   -0.848325 -0.775250 -1.556425 -1.080375 -1.422150 -1.568600 -2.850300  \n17   -0.242825 -0.145200 -0.047525  0.025750 -0.010975 -0.047550 -0.047500  \n18    3.830925  4.441300  4.917400  5.271325  5.442200  5.662050  6.003850  \n19    0.469150  0.444800  0.310600  0.237275  0.164025  0.237250  0.432525  \n20    0.988025  0.646125  0.304375  0.121275  0.218975  0.304325  0.231200  \n21    0.594100  0.471925  0.435300  0.447600  0.386650  0.386575  0.349975  \n22    1.719400  1.426475  0.779475  0.218050  0.169025  0.278950  0.413200  \n23    1.108975  1.194500  0.877050  0.388825  0.156850  0.401050  0.999175  \n24    2.104200  1.628175  0.859050  0.492925  0.737075  0.932400  0.761475  \n25    2.821300  2.381900  1.808075  1.283325  1.026950  1.197825  1.637250  \n26   -1.153300 -1.641625 -0.384325  1.581075  2.740775  2.350050  0.982925  \n27   -0.310700 -0.384025 -0.457300 -0.420625 -0.383925 -0.384025 -0.274175  \n28    0.078875 -0.067625 -0.189775 -0.348400 -0.275100 -0.153100 -0.153000  \n29   -0.644950 -0.388625 -0.229900 -0.229925 -0.290875 -0.290900 -0.303125  \n...        ...       ...       ...       ...       ...       ...       ...  \n4130 -2.078034 -2.364241 -2.515793 -2.515724 -2.246345 -1.859103 -1.471862  \n4131 -1.849207 -1.983966 -2.253448 -2.354483 -2.270172 -2.068172 -1.815552  \n4132 -2.571931 -2.975897 -3.363241 -3.582034 -3.295828 -2.824483 -2.369966  \n4133 -1.616724 -1.482069 -1.515690 -1.481966 -1.364138 -1.212552 -1.010517  \n4134 -0.006310  0.229379  0.077897  0.044207  0.128448  0.515655  1.088241  \n4135 -1.429448 -1.378862 -1.412621 -1.513586 -1.715621 -1.799793 -1.698793  \n4136 -0.692828 -0.591759 -0.423310 -0.137138  0.250069  0.351103  0.250138  \n4137 -0.865621 -0.697379 -0.613103 -0.310138 -0.023862  0.161483 -0.007034  \n4138 -0.946345 -0.980103 -0.879069 -0.710690 -0.424448 -0.272897 -0.373897  \n4139  1.514586  1.548379  1.581931  1.767207  1.935586  1.901862  1.716552  \n4140  0.842207  0.875862  0.993828  1.179000  1.296828  1.296793  1.212586  \n4141  0.880483  1.015172  1.166690  1.402414  1.587552  1.671862  1.436138  \n4142  0.773793  0.925276  1.160966  1.295759  1.531483  1.598759  1.615690  \n4143  0.247172  0.365172  0.567241  0.954517  1.072310  0.971379  0.668241  \n4144 -0.261724  0.007724  0.361207  0.512897  0.613793  0.714931  0.647552  \n4145 -0.759103 -0.641241 -0.506414 -0.254000  0.099552  0.217483  0.015448  \n4146 -1.087379 -0.649655 -0.161379  0.141724  0.326897  0.428069  0.276483  \n4147  0.555276  0.588966  0.656310  0.992931  1.144552  1.195103  0.908828  \n4148  0.081310  0.030897  0.266517  0.502276  0.822276  0.754931  0.620241  \n4149 -0.664793 -0.563690 -0.361586 -0.024828  0.295000  0.446517  0.278138  \n4150 -2.498586 -2.195517 -1.757655 -1.387345 -1.168310 -1.101000 -1.336862  \n4151  1.069414  1.086207  1.204276  1.372621  1.540862  1.591448  1.406276  \n4152  1.827310  1.827241  2.012379  2.096586  2.214414  2.315483  2.063069  \n4153 -1.099276 -0.947793 -0.846690 -0.712138 -0.493103 -0.409034 -0.459448  \n4154 -0.359621 -0.140586  0.145586  0.229759  0.364448  0.448621  0.549690  \n4155 -0.770310 -0.551448 -0.433586 -0.164138  0.088379  0.071517 -0.012690  \n4156 -0.733172 -0.413138 -0.110069  0.209690  0.445552  0.563310  0.529690  \n4157 -3.027517 -3.616862 -4.425069 -4.879759 -4.711345 -3.953621 -2.775000  \n4158 -2.299276 -2.215172 -2.232069 -2.097276 -1.794138 -1.322759 -0.885000  \n4159 -0.699759 -0.615621 -0.430483 -0.059897  0.259966  0.360931  0.259966  \n\n[4160 rows x 257 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordiadan/Google Drive/Uni/QUART/2n Trimestre/Big Data Science/assignment-1-jordiadan_jordiromagosa/venv/lib/python2.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n  \n"
     ]
    }
   ],
   "source": [
    "pca_column_reduction('train_alcoholic_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional Scaling (MDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# read data\n",
    "df = read_row_reduction_data('train_alcoholic_rows')\n",
    "    \n",
    "# split data table into data X and class labels y\n",
    "X_true = df.ix[:, 1:].values\n",
    "y = df.ix[:, 0].values\n",
    "\n",
    "# Center the data\n",
    "X_true -= X_true.mean()\n",
    "print(X_true)\n",
    "\n",
    "similarities = euclidean_distances(X_true)\n",
    "\n",
    "# Add noise to the similarities\n",
    "noise = np.random.rand(n_samples, n_samples)\n",
    "noise = noise + noise.T\n",
    "noise[np.arange(noise.shape[0]), np.arange(noise.shape[0])] = 0\n",
    "similarities += noise\n",
    "\n",
    "mds = manifold.MDS(n_components=2, max_iter=3000, eps=1e-9, random_state=seed,\n",
    "                   dissimilarity=\"precomputed\", n_jobs=1)\n",
    "pos = mds.fit(similarities).embedding_\n",
    "\n",
    "nmds = manifold.MDS(n_components=2, metric=False, max_iter=3000, eps=1e-12,\n",
    "                    dissimilarity=\"precomputed\", random_state=seed, n_jobs=1,\n",
    "                    n_init=1)\n",
    "npos = nmds.fit_transform(similarities, init=pos)\n",
    "\n",
    "# Rescale the data\n",
    "pos *= np.sqrt((X_true ** 2).sum()) / np.sqrt((pos ** 2).sum())\n",
    "npos *= np.sqrt((X_true ** 2).sum()) / np.sqrt((npos ** 2).sum())\n",
    "\n",
    "# Rotate the data\n",
    "clf = PCA(n_components=2)\n",
    "X_true = clf.fit_transform(X_true)\n",
    "\n",
    "pos = clf.fit_transform(pos)\n",
    "\n",
    "npos = clf.fit_transform(npos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
