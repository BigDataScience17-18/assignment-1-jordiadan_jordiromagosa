{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "### Authors\n",
    "* Jordi Mellado Romagosa \n",
    "* Jordi Adan Dom√≠nguez\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    # read data\n",
    "    return pd.read_csv(filepath_or_buffer='model_files/' + filename + '.csv',\n",
    "                       sep=\",\",\n",
    "                       low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "### PCA (with row reduction)\n",
    "\n",
    "columns = ['Min', 'Max', 'Sd', 'Mean', 'Median', 'IQR', 'Q(0.025)', 'Q(0.25)', 'Q(0.75)', 'Q(0.975)']  \n",
    "rows = Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_row_reduction(filename):\n",
    "    \n",
    "    # read data\n",
    "    df = read_data(filename)\n",
    "    \n",
    "    # drop String type columns\n",
    "    df.drop(df.columns[[0, 2, 4]], axis=1, inplace=True)\n",
    "    \n",
    "    # split data table into data X and class labels y\n",
    "    X = df.iloc[:, 1:].values\n",
    "    y = df.iloc[:, 0].values\n",
    "    \n",
    "    # standardizing data\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    sklearn_pca = PCA(svd_solver='auto')\n",
    "    Y_sklearn = sklearn_pca.fit_transform(X_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (with column reduction)\n",
    "\n",
    "columns = Sensor value records(255)  \n",
    "rows = Average of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_column_reduction(filename):\n",
    "    \n",
    "    # read data\n",
    "    df = read_data(filename)\n",
    "    print(df)\n",
    "    \n",
    "    # drop String type columns\n",
    "    df.drop(df.columns[[0, 2, 3]], axis=1, inplace=True)\n",
    "\n",
    "    # split data table into data X and class labels y\n",
    "    X = df.iloc[:, 4:].values\n",
    "    y = df.iloc[:, 1].values\n",
    "    \n",
    "    # standardizing data\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    sklearn_pca = PCA(svd_solver='auto')\n",
    "    Y_sklearn = sklearn_pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_row_reduction('train_1_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Id  Alcoholic   Paradigm    Channel  Reading 1  Reading 2  \\\n",
      "0     co2a0000364       True      S1obj   AF1chan4  -0.653350  -0.592275   \n",
      "1     co2a0000364       True      S1obj   AF2chan5  -0.233000  -0.269600   \n",
      "2     co2a0000364       True      S1obj  AF7chan32  -2.521950  -1.398925   \n",
      "3     co2a0000364       True      S1obj  AF8chan33  -0.150550  -1.334600   \n",
      "4     co2a0000364       True      S1obj  AFZchan47  -0.446850  -0.446850   \n",
      "5     co2a0000364       True      S1obj   C1chan52   0.774675   0.103275   \n",
      "6     co2a0000364       True      S1obj   C2chan53   0.369975  -0.338025   \n",
      "7     co2a0000364       True      S1obj   C3chan16   0.770075  -0.047750   \n",
      "8     co2a0000364       True      S1obj   C4chan17  -0.285850  -0.932825   \n",
      "9     co2a0000364       True      S1obj   C5chan42   0.291675   0.267375   \n",
      "10    co2a0000364       True      S1obj   C6chan41   0.527750   0.271375   \n",
      "11    co2a0000364       True      S1obj  CP1chan20   0.101225   0.247700   \n",
      "12    co2a0000364       True      S1obj  CP2chan21   0.306475   0.294325   \n",
      "13    co2a0000364       True      S1obj  CP3chan48   0.411500   0.667900   \n",
      "14    co2a0000364       True      S1obj  CP4chan49   0.477575   0.404350   \n",
      "15    co2a0000364       True      S1obj  CP5chan18  -0.377175  -1.194975   \n",
      "16    co2a0000364       True      S1obj  CP6chan19   0.103700  -1.092425   \n",
      "17    co2a0000364       True      S1obj  CPZchan61   0.257575   0.306450   \n",
      "18    co2a0000364       True      S1obj   CZchan15   0.767025   2.073175   \n",
      "19    co2a0000364       True      S1obj   F1chan44  -0.373075  -0.238800   \n",
      "20    co2a0000364       True      S1obj   F2chan43   0.011400  -0.061725   \n",
      "21    co2a0000364       True      S1obj    F3chan8  -0.663275  -0.370275   \n",
      "22    co2a0000364       True      S1obj    F4chan7   0.352150   0.120300   \n",
      "23    co2a0000364       True      S1obj   F5chan34  -0.746375  -0.355825   \n",
      "24    co2a0000364       True      S1obj   F6chan35   0.932300   0.419625   \n",
      "25    co2a0000364       True      S1obj    F7chan2  -1.084825  -0.462350   \n",
      "26    co2a0000364       True      S1obj    F8chan3   0.689900   1.153775   \n",
      "27    co2a0000364       True      S1obj  FC1chan12  -0.408450  -0.322950   \n",
      "28    co2a0000364       True      S1obj  FC2chan11   0.029975  -0.006625   \n",
      "29    co2a0000364       True      S1obj  FC3chan40  -0.571725  -0.229975   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "4514  co2c0000347      False  S2nomatch   FP1chan0   2.469136   1.492545   \n",
      "4515  co2c0000347      False  S2nomatch   FP2chan1   0.745455  -0.009227   \n",
      "4516  co2c0000347      False  S2nomatch  FPZchan38   1.621091   1.332773   \n",
      "4517  co2c0000347      False  S2nomatch  FT7chan36  -0.446636   0.063864   \n",
      "4518  co2c0000347      False  S2nomatch  FT8chan37   0.599273   0.621409   \n",
      "4519  co2c0000347      False  S2nomatch    FZchan6   1.020909   0.843455   \n",
      "4520  co2c0000347      False  S2nomatch   O1chan30   0.218682   0.529455   \n",
      "4521  co2c0000347      False  S2nomatch   O2chan29   0.645909   1.023318   \n",
      "4522  co2c0000347      False  S2nomatch   OZchan58   0.542909   0.897909   \n",
      "4523  co2c0000347      False  S2nomatch   P1chan60  -0.153591   0.157227   \n",
      "4524  co2c0000347      False  S2nomatch   P2chan59   0.396773   0.840591   \n",
      "4525  co2c0000347      False  S2nomatch   P3chan22  -0.473500  -0.251500   \n",
      "4526  co2c0000347      False  S2nomatch   P4chan23   0.600545   1.022409   \n",
      "4527  co2c0000347      False  S2nomatch   P5chan50  -0.461500  -0.461455   \n",
      "4528  co2c0000347      False  S2nomatch   P6chan51   0.914091   1.091636   \n",
      "4529  co2c0000347      False  S2nomatch   P7chan26  -0.689000  -0.378273   \n",
      "4530  co2c0000347      False  S2nomatch   P8chan25   0.359364   0.847409   \n",
      "4531  co2c0000347      False  S2nomatch  PO1chan28  -0.073136   0.259818   \n",
      "4532  co2c0000347      False  S2nomatch  PO2chan27   0.679636   1.145727   \n",
      "4533  co2c0000347      False  S2nomatch  PO7chan54  -0.322182  -0.011636   \n",
      "4534  co2c0000347      False  S2nomatch  PO8chan55   0.573727   0.951091   \n",
      "4535  co2c0000347      False  S2nomatch  POZchan57   0.315409   0.670455   \n",
      "4536  co2c0000347      False  S2nomatch   PZchan24   0.189955   0.633955   \n",
      "4537  co2c0000347      False  S2nomatch   T7chan14   0.885955   0.908136   \n",
      "4538  co2c0000347      False  S2nomatch   T8chan13   0.129864   0.729182   \n",
      "4539  co2c0000347      False  S2nomatch  TP7chan46  -0.613591  -0.813318   \n",
      "4540  co2c0000347      False  S2nomatch  TP8chan45   0.172000   0.593682   \n",
      "4541  co2c0000347      False  S2nomatch    Xchan31   2.579636   5.931045   \n",
      "4542  co2c0000347      False  S2nomatch    Ychan63  -0.035955   0.430091   \n",
      "4543  co2c0000347      False  S2nomatch   ndchan62   0.304727   0.571045   \n",
      "\n",
      "      Reading 3  Reading 4  Reading 5  Reading 6     ...       Reading 247  \\\n",
      "0     -0.543350  -0.567950  -0.519050  -0.519050     ...          4.070825   \n",
      "1     -0.428225  -0.367225  -0.086500   0.084450     ...          3.099525   \n",
      "2      0.004800   0.883775   0.761700  -0.080600     ...          7.390100   \n",
      "3     -1.615350  -0.834150   0.276650   0.447575     ...          7.588675   \n",
      "4     -0.507900  -0.349100  -0.166050  -0.104975     ...          3.569200   \n",
      "5      0.200975   0.286350   0.945525   0.139825     ...         -0.751250   \n",
      "6     -0.167075  -0.350225   0.064850   0.125925     ...          0.260225   \n",
      "7      0.428275  -0.230925   0.965350  -1.109850     ...         -1.781175   \n",
      "8     -0.542250  -1.042675  -0.481125   0.214625     ...          0.458825   \n",
      "9      0.364950   0.584750   0.609100   0.120775     ...         -2.515900   \n",
      "10     0.002825  -0.229100  -0.424475  -0.509950     ...         -0.937150   \n",
      "11     0.357500   0.418550   0.333125   0.247650     ...         -0.692250   \n",
      "12     0.343075   0.343050   0.269800   0.160000     ...         -0.218450   \n",
      "13     0.667825   0.387000   0.069650  -0.015725     ...         -1.529475   \n",
      "14     0.367600   0.331100   0.160250   0.050300     ...         -1.255825   \n",
      "15    -1.207250   0.452900   0.269850   1.795700     ...         -2.269225   \n",
      "16    -1.617400  -1.483075  -0.567550   0.482100     ...         -1.776200   \n",
      "17     0.416250   0.428550   0.416325   0.404025     ...         -0.462575   \n",
      "18     3.757700   5.137150   5.503325   4.563425     ...          2.988675   \n",
      "19    -0.141125  -0.043425   0.005300  -0.067875     ...          0.676750   \n",
      "20    -0.122800  -0.159450  -0.232700  -0.305975     ...          0.109125   \n",
      "21    -0.101700   0.081375   0.093600   0.020375     ...          0.874775   \n",
      "22    -0.136100  -0.441325  -0.734200  -0.856225     ...         -0.050575   \n",
      "23     0.059225   0.156900   0.132425  -0.026225     ...          1.011350   \n",
      "24    -0.190650  -0.752200  -1.338125  -1.679950     ...          0.212075   \n",
      "25     0.331100   1.112325   1.283225   0.758300     ...          2.503900   \n",
      "26     0.665500  -0.323275  -0.896925  -0.884825     ...          4.620600   \n",
      "27    -0.066625   0.104225   0.079875  -0.066575     ...         -0.286400   \n",
      "28    -0.055500  -0.140975  -0.275125  -0.458325     ...         -0.397225   \n",
      "29    -0.034650   0.136325   0.197350   0.160700     ...         -0.535050   \n",
      "...         ...        ...        ...        ...     ...               ...   \n",
      "4514   0.626909   0.626909   1.559091   2.735545     ...          4.422227   \n",
      "4515   0.234909   1.122636   2.010455   2.188000     ...          2.543091   \n",
      "4516   0.822227   0.666773   0.910909   1.487955     ...          3.419045   \n",
      "4517   0.396727   0.285864  -0.180273  -0.402227     ...         -0.868318   \n",
      "4518   0.266364  -0.044273  -0.310682  -0.310727     ...         -2.974091   \n",
      "4519   0.776864   0.843364   1.043227   1.176409     ...         -0.133091   \n",
      "4520   0.418545  -0.136409  -0.713500  -0.891000     ...         -4.419864   \n",
      "4521   1.023182   0.712500   0.357455   0.135545     ...         -4.214636   \n",
      "4522   0.853591   0.476273  -0.034273  -0.411500     ...         -4.606364   \n",
      "4523   0.112864  -0.242273  -0.508591  -0.708318     ...         -1.729455   \n",
      "4524   1.040364   0.840545   0.463273   0.041636     ...         -1.489909   \n",
      "4525  -0.384727  -0.739909  -1.028318  -1.050545     ...         -2.115909   \n",
      "4526   1.088955   0.866909   0.445273   0.223409     ...         -1.219318   \n",
      "4527  -0.661227  -0.994045  -1.127318  -0.949864     ...         -1.660000   \n",
      "4528   1.091773   0.803091   0.558909   0.403682     ...         -0.928045   \n",
      "4529  -0.400455  -0.711182  -0.933000  -0.844364     ...         -1.354818   \n",
      "4530   0.914227   0.869818   0.470318   0.115091     ...         -1.793636   \n",
      "4531   0.282136  -0.073000  -0.428227  -0.628000     ...         -2.780727   \n",
      "4532   1.234455   0.946045   0.590864   0.169273     ...         -2.627273   \n",
      "4533  -0.167000  -0.522136  -0.877136  -0.988136     ...         -2.652682   \n",
      "4534   0.973364   0.973318   0.662636   0.418455     ...         -3.177045   \n",
      "4535   0.670500   0.337455  -0.039682  -0.372636     ...         -3.036000   \n",
      "4536   0.745000   0.500727   0.079091  -0.231727     ...         -1.252591   \n",
      "4537  -0.001955  -1.289136  -2.043773  -1.843955     ...         -2.776136   \n",
      "4538   0.773591   0.462818   0.041136  -0.136318     ...         -2.644455   \n",
      "4539  -1.190682  -1.279455  -1.057591  -0.502545     ...         -1.745500   \n",
      "4540   0.726818   0.482682   0.194136  -0.138636     ...         -1.670227   \n",
      "4541   6.619045   4.355136   0.892909  -1.149045     ...          8.328000   \n",
      "4542   0.518773   0.252500  -0.058318  -0.324727     ...         -4.053227   \n",
      "4543   0.349091  -0.139182  -0.627455  -0.827136     ...         -4.333909   \n",
      "\n",
      "      Reading 248  Reading 249  Reading 250  Reading 251  Reading 252  \\\n",
      "0        3.912075     4.009700     4.034100     3.692425     3.301625   \n",
      "1        2.794350     2.843175     3.038500     3.185025     3.111775   \n",
      "2        7.414475     7.512175     7.353475     6.828475     6.096200   \n",
      "3        6.172675     4.134200     2.718100     2.376250     3.108800   \n",
      "4        3.361700     3.386275     3.459525     3.447175     3.337350   \n",
      "5       -0.531450    -0.397175    -0.629200    -1.825500    -0.030925   \n",
      "6        0.235750     0.150250     0.162500    -0.948375    -0.118300   \n",
      "7       -1.012175    -0.523850    -0.316425    -0.499400    -0.133275   \n",
      "8        0.568675    -0.017375    -0.237025     1.484150    -0.737475   \n",
      "9       -2.076525    -1.112075    -0.514000    -0.880150    -1.685825   \n",
      "10      -1.083625    -1.010425    -0.876200    -0.888400    -0.937150   \n",
      "11      -0.728900    -0.765550    -0.606775    -0.387100    -0.313900   \n",
      "12      -0.230600    -0.145225    -0.108625     0.123350     0.233175   \n",
      "13      -1.529400    -1.614875    -1.505025    -1.309700    -1.065575   \n",
      "14      -1.219150    -1.231350    -1.158175    -1.060475    -0.865125   \n",
      "15      -1.268150    -1.109550    -1.195050    -2.452350    -2.049500   \n",
      "16      -1.629650    -1.739425    -0.848325    -0.775250    -1.556425   \n",
      "17      -0.425950    -0.425950    -0.242825    -0.145200    -0.047525   \n",
      "18       2.976475     3.330375     3.830925     4.441300     4.917400   \n",
      "19       0.481425     0.469200     0.469150     0.444800     0.310600   \n",
      "20       0.597400     0.939175     0.988025     0.646125     0.304375   \n",
      "21       0.789450     0.667275     0.594100     0.471925     0.435300   \n",
      "22       0.571900     1.341050     1.719400     1.426475     0.779475   \n",
      "23       0.779450     0.889400     1.108975     1.194500     0.877050   \n",
      "24       1.115350     1.933300     2.104200     1.628175     0.859050   \n",
      "25       2.650475     2.894525     2.821300     2.381900     1.808075   \n",
      "26       3.338800     0.958450    -1.153300    -1.641625    -0.384325   \n",
      "27      -0.274150    -0.261975    -0.310700    -0.384025    -0.457300   \n",
      "28      -0.238600    -0.079875     0.078875    -0.067625    -0.189775   \n",
      "29      -0.779225    -0.803700    -0.644950    -0.388625    -0.229900   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "4514     4.067136     4.333591     4.888364     5.265682     4.999273   \n",
      "4515     3.763818     4.451818     4.607182     4.274318     3.652909   \n",
      "4516     3.862773     4.661773     5.283227     5.394273     5.083455   \n",
      "4517    -1.023682    -1.312273    -1.512045    -1.245636    -0.690773   \n",
      "4518    -2.352545    -1.797727    -1.753318    -2.041955    -2.508000   \n",
      "4519    -0.155455    -0.399682    -0.599227    -0.798955    -0.821318   \n",
      "4520    -3.754182    -3.332409    -3.310318    -3.643136    -4.175864   \n",
      "4521    -3.193682    -2.461273    -2.194955    -2.483409    -3.060455   \n",
      "4522    -3.763000    -3.208045    -2.963818    -3.296773    -3.785136   \n",
      "4523    -1.352045    -1.196636    -1.241091    -1.418545    -1.662773   \n",
      "4524    -0.824000    -0.358000    -0.224727    -0.468955    -1.001591   \n",
      "4525    -1.916182    -1.694227    -1.716318    -1.916136    -2.249000   \n",
      "4526    -0.464727     0.112364     0.245455     0.001455    -0.553409   \n",
      "4527    -1.304818    -1.105136    -1.193818    -1.504682    -1.859773   \n",
      "4528    -0.151273     0.248318     0.314909    -0.018091    -0.617318   \n",
      "4529    -0.977455    -0.910955    -0.888727    -1.132773    -1.532409   \n",
      "4530    -0.905864    -0.239909     0.026409    -0.128909    -0.639409   \n",
      "4531    -2.381227    -2.092727    -2.137000    -2.425682    -2.914000   \n",
      "4532    -1.739455    -1.184682    -1.140182    -1.451000    -2.050273   \n",
      "4533    -2.164409    -1.787136    -1.853727    -2.364136    -2.896818   \n",
      "4534    -2.000727    -1.157500    -0.802273    -1.002000    -1.667773   \n",
      "4535    -2.458955    -2.015182    -1.948364    -2.326000    -2.814136   \n",
      "4536    -0.830909    -0.475818    -0.498000    -0.586773    -0.964136   \n",
      "4537    -2.132500    -1.688682    -1.710864    -1.910636    -1.777409   \n",
      "4538    -2.023136    -1.290591    -0.957636    -0.646864    -0.824318   \n",
      "4539    -1.590182    -1.479182    -1.235000    -1.168409    -1.412591   \n",
      "4540    -1.137545    -0.604727    -0.471682    -0.627000    -0.871182   \n",
      "4541     7.972909     8.905091    10.369955    10.902636    10.059364   \n",
      "4542    -4.031182    -4.053364    -3.764727    -3.365227    -3.121091   \n",
      "4543    -3.557182    -3.091000    -2.980136    -3.401773    -3.978773   \n",
      "\n",
      "      Reading 253  Reading 254  Reading 255  Reading 256  \n",
      "0        3.008750     3.021025     3.387175     3.704550  \n",
      "1        2.940900     2.867650     3.062875     3.404800  \n",
      "2        5.510200     5.620000     6.096050     6.572225  \n",
      "3        4.207350     5.330375     6.197200     6.624350  \n",
      "4        3.129800     2.971125     3.032150     3.203025  \n",
      "5       -0.555900    -0.446075    -0.470500    -0.006650  \n",
      "6        0.321200    -0.057225     0.748375    -0.191500  \n",
      "7       -1.195250    -0.694875    -1.366200     0.281775  \n",
      "8        1.508575     0.202500     1.447575    -0.847375  \n",
      "9       -2.161925    -1.893350    -1.222050    -0.965600  \n",
      "10      -0.924925    -0.656375    -0.265800    -0.021700  \n",
      "11      -0.240600    -0.338325    -0.533600    -0.558000  \n",
      "12       0.306550     0.379725     0.257625     0.294300  \n",
      "13      -0.992300    -1.138850    -1.346300    -1.431725  \n",
      "14      -0.706525    -0.572175    -0.572175    -0.535575  \n",
      "15      -2.989400    -2.806350    -0.584625    -0.462575  \n",
      "16      -1.080375    -1.422150    -1.568600    -2.850300  \n",
      "17       0.025750    -0.010975    -0.047550    -0.047500  \n",
      "18       5.271325     5.442200     5.662050     6.003850  \n",
      "19       0.237275     0.164025     0.237250     0.432525  \n",
      "20       0.121275     0.218975     0.304325     0.231200  \n",
      "21       0.447600     0.386650     0.386575     0.349975  \n",
      "22       0.218050     0.169025     0.278950     0.413200  \n",
      "23       0.388825     0.156850     0.401050     0.999175  \n",
      "24       0.492925     0.737075     0.932400     0.761475  \n",
      "25       1.283325     1.026950     1.197825     1.637250  \n",
      "26       1.581075     2.740775     2.350050     0.982925  \n",
      "27      -0.420625    -0.383925    -0.384025    -0.274175  \n",
      "28      -0.348400    -0.275100    -0.153100    -0.153000  \n",
      "29      -0.229925    -0.290875    -0.290900    -0.303125  \n",
      "...           ...          ...          ...          ...  \n",
      "4514     4.488864     3.867500     3.889591     4.644182  \n",
      "4515     2.676318     1.566500     0.900682     1.033864  \n",
      "4516     4.639636     4.240136     4.395364     5.039091  \n",
      "4517    -0.158091     0.197045    -0.002727    -0.313455  \n",
      "4518    -2.885318    -3.196045    -3.373682    -3.284682  \n",
      "4519    -0.776773    -0.688045    -0.577045    -0.377273  \n",
      "4520    -4.664045    -5.041364    -5.196727    -4.930364  \n",
      "4521    -3.726409    -4.392227    -4.902636    -5.035818  \n",
      "4522    -4.450909    -4.961273    -5.272136    -5.338818  \n",
      "4523    -1.929045    -2.195455    -2.395136    -2.395227  \n",
      "4524    -1.445455    -2.022591    -2.355364    -2.444182  \n",
      "4525    -2.515500    -2.626318    -2.626364    -2.515500  \n",
      "4526    -1.152682    -1.685318    -2.085000    -2.151545  \n",
      "4527    -2.015000    -2.037364    -1.704364    -1.371455  \n",
      "4528    -1.327455    -1.838045    -2.215227    -2.304091  \n",
      "4529    -1.820909    -1.820864    -1.421409    -0.822182  \n",
      "4530    -1.394091    -2.015591    -2.348545    -2.348455  \n",
      "4531    -3.246909    -3.491000    -3.668591    -3.646409  \n",
      "4532    -2.716091    -3.315318    -3.692636    -3.848000  \n",
      "4533    -3.429545    -3.474000    -3.251955    -2.652682  \n",
      "4534    -2.600045    -3.354545    -3.798591    -3.976091  \n",
      "4535    -3.280227    -3.679682    -3.968136    -4.145818  \n",
      "4536    -1.408045    -1.629818    -1.940682    -2.184818  \n",
      "4537    -1.244818    -0.578909    -0.312545    -0.334727  \n",
      "4538    -1.334955    -1.978500    -2.666545    -2.977364  \n",
      "4539    -1.967364    -2.122818    -1.967409    -1.212818  \n",
      "4540    -1.359409    -1.869864    -2.291591    -2.269364  \n",
      "4541     8.749682     8.461273     9.881636    11.945818  \n",
      "4542    -3.210000    -3.254227    -3.232091    -2.943500  \n",
      "4543    -4.600318    -4.955409    -4.911045    -4.800091  \n",
      "\n",
      "[4544 rows x 260 columns]\n"
     ]
    }
   ],
   "source": [
    "pca_column_reduction('train_1_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional Scaling (MDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rows():\n",
    "    # Training set\n",
    "    train = read_data('train_1_rows')\n",
    "\n",
    "    #train.drop(train.columns[[0, 2, 4]], axis=1, inplace=True)\n",
    "    train.drop(train.columns[[0]], axis=1, inplace=True)\n",
    "\n",
    "    X_train = train.iloc[:, 1:]\n",
    "    X_train = pd.get_dummies(X_train)\n",
    "    y_train = train[\"Alcoholic\"]\n",
    "    \n",
    "    # Show Regression Analysis Results \n",
    "    #implementing_model(X_train, y_train)\n",
    "    \n",
    "    # Test set\n",
    "    test = read_data('test_1_rows')\n",
    "    \n",
    "    #test.drop(test.columns[[0, 2, 4]], axis=1, inplace=True)\n",
    "    test.drop(test.columns[[0]], axis=1, inplace=True)\n",
    "    \n",
    "    X_test = test.iloc[:, 1:]\n",
    "    X_test = pd.get_dummies(X_test)\n",
    "    y_test = test[\"Alcoholic\"]\n",
    "    \n",
    "    #logistic_regression_model_fitting(X_train, X_test, y_train, y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df: stats.chi2.sf(chisq, df)\n",
    "\n",
    "def implementing_model_results(X, y):\n",
    "    logit_model = sm.Logit(y,X)\n",
    "    result = logit_model.fit(warnings=False)\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.605271\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              Alcoholic   No. Observations:               192896\n",
      "Model:                          Logit   Df Residuals:                   192818\n",
      "Method:                           MLE   Df Model:                           77\n",
      "Date:                Wed, 21 Mar 2018   Pseudo R-squ.:                 0.03504\n",
      "Time:                        18:46:16   Log-Likelihood:            -1.1675e+05\n",
      "converged:                      False   LL-Null:                   -1.2099e+05\n",
      "                                        LLR p-value:                     0.000\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Replication              -0.0030      0.000    -20.264      0.000      -0.003      -0.003\n",
      "Min                       0.0010      0.002      0.425      0.671      -0.004       0.006\n",
      "Max                      -0.0173      0.002    -10.639      0.000      -0.020      -0.014\n",
      "Sd                        0.3385      0.017     20.435      0.000       0.306       0.371\n",
      "Mean                     -0.0139      0.024     -0.574      0.566      -0.061       0.034\n",
      "Median                    0.0457      0.008      5.625      0.000       0.030       0.062\n",
      "IQR                       0.1566      0.005     30.073      0.000       0.146       0.167\n",
      "Q(0.025)                 -0.0327   5.25e+04  -6.22e-07      1.000   -1.03e+05    1.03e+05\n",
      "Q(0.25)                  -0.0612   5.25e+04  -1.16e-06      1.000   -1.03e+05    1.03e+05\n",
      "Q(0.75)                  -0.0653      0.004    -15.440      0.000      -0.074      -0.057\n",
      "Q(0.975)                 -0.0261   5.25e+04  -4.96e-07      1.000   -1.03e+05    1.03e+05\n",
      "Paradigm_S1obj            1.7998   2.22e+05    8.1e-06      1.000   -4.35e+05    4.35e+05\n",
      "Paradigm_S2match          1.9363   2.22e+05   8.72e-06      1.000   -4.35e+05    4.35e+05\n",
      "Paradigm_S2matcherr       2.3210   2.22e+05   1.04e-05      1.000   -4.35e+05    4.35e+05\n",
      "Paradigm_S2nomatch        1.8512   2.22e+05   8.33e-06      1.000   -4.35e+05    4.35e+05\n",
      "Paradigm_S2nomatcherr     3.5340   2.22e+05   1.59e-05      1.000   -4.35e+05    4.35e+05\n",
      "Channel_AF1chan4          0.1880   2.22e+05   8.46e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_AF2chan5          0.1715   2.22e+05   7.72e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_AF7chan32         0.5703   2.22e+05   2.57e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_AF8chan33         0.5937   2.22e+05   2.67e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_AFZchan47         0.1370   2.22e+05   6.17e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_C1chan52         -0.5356   2.22e+05  -2.41e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_C2chan53         -0.5370   2.22e+05  -2.42e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_C3chan16         -0.2391   2.22e+05  -1.08e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_C4chan17         -0.2605   2.22e+05  -1.17e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_C5chan42         -0.0037   2.22e+05  -1.67e-08      1.000   -4.35e+05    4.35e+05\n",
      "Channel_C6chan41         -0.0104   2.22e+05  -4.67e-08      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CP1chan20        -0.3987   2.22e+05   -1.8e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CP2chan21        -0.3709   2.22e+05  -1.67e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CP3chan48        -0.1706   2.22e+05  -7.68e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CP4chan49        -0.1735   2.22e+05  -7.81e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CP5chan18         0.1306   2.22e+05   5.88e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CP6chan19         0.0967   2.22e+05   4.35e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CPZchan61        -0.4528   2.22e+05  -2.04e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_CZchan15          1.2281   2.22e+05   5.53e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F1chan44         -0.0637   2.22e+05  -2.87e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F2chan43         -0.0763   2.22e+05  -3.43e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F3chan8          -0.0058   2.22e+05  -2.61e-08      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F4chan7           0.0365   2.22e+05   1.64e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F5chan34          0.2258   2.22e+05   1.02e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F6chan35          0.2437   2.22e+05    1.1e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F7chan2           0.5023   2.22e+05   2.26e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_F8chan3           0.5482   2.22e+05   2.47e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FC1chan12        -0.3891   2.22e+05  -1.75e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FC2chan11        -0.4118   2.22e+05  -1.85e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FC3chan40        -0.2306   2.22e+05  -1.04e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FC4chan39        -0.2198   2.22e+05   -9.9e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FC5chan10         0.0901   2.22e+05   4.06e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FC6chan9          0.0699   2.22e+05   3.15e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FCZchan56        -0.4323   2.22e+05  -1.95e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FP1chan0          0.7843   2.22e+05   3.53e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FP2chan1          0.5213   2.22e+05   2.35e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FPZchan38         0.4642   2.22e+05   2.09e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FT7chan36         0.4309   2.22e+05   1.94e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FT8chan37         0.3696   2.22e+05   1.66e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_FZchan6          -0.0922   2.22e+05  -4.15e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_O1chan30          0.5627   2.22e+05   2.53e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_O2chan29          0.5232   2.22e+05   2.36e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_OZchan58          0.4892   2.22e+05    2.2e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P1chan60         -0.0272   2.22e+05  -1.22e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P2chan59          0.0289   2.22e+05    1.3e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P3chan22          0.0727   2.22e+05   3.27e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P4chan23          0.0773   2.22e+05   3.48e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P5chan50          0.2488   2.22e+05   1.12e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P6chan51          0.2819   2.22e+05   1.27e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P7chan26          0.4606   2.22e+05   2.07e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_P8chan25          0.4613   2.22e+05   2.08e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_PO1chan28         0.2711   2.22e+05   1.22e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_PO2chan27         0.3562   2.22e+05    1.6e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_PO7chan54         0.7731   2.22e+05   3.48e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_PO8chan55         0.6859   2.22e+05   3.09e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_POZchan57         0.2412   2.22e+05   1.09e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_PZchan24         -0.0858   2.22e+05  -3.86e-07      1.000   -4.35e+05    4.35e+05\n",
      "Channel_T7chan14          0.3467   2.22e+05   1.56e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_T8chan13          0.4497   2.22e+05   2.02e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_TP7chan46         0.3889   2.22e+05   1.75e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_TP8chan45         0.3808   2.22e+05   1.71e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_Xchan31           0.9522   2.22e+05   4.29e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_Ychan63           0.6781   2.22e+05   3.05e-06      1.000   -4.35e+05    4.35e+05\n",
      "Channel_ndchan62          0.4965   2.22e+05   2.24e-06      1.000   -4.35e+05    4.35e+05\n",
      "=========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordiadan/Google Drive/Uni/QUART/2n Trimestre/Big Data Science/assignment-1-jordiadan_jordiromagosa/venv/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "implementing_model_results(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can consider that P-values greater than 0.05 are insignificant. The best labels are:\n",
    "* Replication\n",
    "* Min\n",
    "* Max\n",
    "* Mean\n",
    "* IQR\n",
    "* Q(0.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def logistic_regression_model_fitting(X_train, X_test, y_train, y_test):\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    logreg = linear_model.LogisticRegression()\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "    return y_pred;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.62\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic_regression_model_fitting(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.648\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "modelCV = linear_model.LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13674 39702]\n",
      " [ 5483 58581]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is telling us that we have 13651 + 58594 correct predictions and 5470 + 39725 incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute precision, recall, F-measure and support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.71      0.26      0.38     53376\n",
      "       True       0.60      0.91      0.72     64064\n",
      "\n",
      "avg / total       0.65      0.62      0.57    117440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
